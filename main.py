# -*- coding: utf-8 -*-
"""Очередь на границе.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j1_klDOeWuwKjw9EuBuiZuxvfPHWeZNE
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# 
# # установим нужную библиотеку
# !pip install ultralytics

# подключим библиотеку
import cv2
import os
import asyncio
import websockets
import time
import os
from datetime import datetime
from ultralytics import YOLOWorld

# используем предобученную модель
model = YOLOWorld("yolov8s-world")

# классы объектов, которые модель умеет выделять:
# model.names

model.set_classes(["person, car"])

# !pip install  


def detect_objects(path, conf):
  results = model.predict(
      path,
      conf=conf  # помечать только объекты, относящиеся к классу с вероятностью от 0.3
  )
  results[0].save(filename="./frames/result.jpg")
  
  return (results[0].summary())


# Function to extract frames
def extract_frames(video_path, output_folder, num_frames):
    # Check if output directory exists, if not, create it
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Open the video file
    cap = cv2.VideoCapture(video_path)

    # Get total number of frames in the video
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    print(f"Total frames in video: {total_frames}")

    # Calculate the interval between frames to extract to get `num_frames` evenly spaced frames
    interval = total_frames // num_frames

    # Counter for the frames
    count = 0
    extracted = 0

    while cap.isOpened() and extracted < num_frames:
        ret, frame = cap.read()
        if not ret:
            break

        # Save the frame if it is one of the target frames
        if count % interval == 0:
            frame_filename = os.path.join(output_folder, f"frame_{extracted+1}.jpg")
            cv2.imwrite(frame_filename, frame)
            print(f"Saved: {frame_filename}")
            extracted += 1

        count += 1

    # Release the video capture object
    cap.release()
    print("Frame extraction completed.")



async def save_video_stream(interval_seconds=30):
    url = "wss://sr-171-25-232-21.ipeye.ru/ws/mp4/live?name=419ad06fb33f4c97b5deca110889c70f&mode=live"

    headers = {
        'Upgrade': 'websocket',
        'Origin': 'https://ipeye.ru',
        'Cache-Control': 'no-cache',
        'Accept-Language': 'en-US,en;q=0.9,ru;q=0.8',
        'Pragma': 'no-cache',
        'Connection': 'Upgrade',
        'Sec-WebSocket-Key': 'bof4xYu+I2uGw/LSKCbsHg==',
        'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Mobile Safari/537.36',
        'Sec-WebSocket-Version': '13',
        'Sec-WebSocket-Extensions': 'permessage-deflate; client_max_window_bits'
    }

    output_dir = "video_chunks"
    os.makedirs(output_dir, exist_ok=True)

    # MP4 file signature (hex)
    MP4_HEADER = bytes.fromhex('00 00 00 20 66 74 79 70')
    MP4_MOOV = bytes.fromhex('6D 6F 6F 76')
    MP4_MDAT = bytes.fromhex('6D 64 61 74')

    try:
        while True:
            async with websockets.connect(url, extra_headers=headers) as websocket:
                print("Connected to WebSocket stream")

                chunk_data = bytearray()
                start_time = time.time()
                is_recording = False

                while True:
                    try:
                        data = await websocket.recv()

                        # Look for MP4 header or segments
                        if MP4_HEADER in data or MP4_MOOV in data or MP4_MDAT in data:
                            if not is_recording:
                                is_recording = True
                                chunk_data = bytearray()
                                start_time = time.time()

                        if is_recording:
                            chunk_data.extend(data)

                            current_time = time.time()
                            if current_time - start_time >= interval_seconds:
                                # Generate filename with timestamp
                                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                filename = f"{output_dir}/video_chunk_{timestamp}.mp4"

                                # Save only if we have enough data
                                if len(chunk_data) > 1024:  # Minimum size check
                                    with open(filename, "wb") as f:
                                        f.write(chunk_data)
                                    print(f"Saved video chunk: {filename} - Size: {len(chunk_data)/1024:.2f} KB")
                                    extract_frames(filename, "./frames", 1)
                                    res = detect_objects("./frames/frame_1.jpg", 0.3)
                                    print("detected: ", res)
                                    break

                    except websockets.exceptions.ConnectionClosed:
                        print("Connection closed, attempting to reconnect...")
                        break

    except Exception as e:
        print(f"Error: {e}")

async def main():
    while True:
        try:
            await save_video_stream(interval_seconds=10)  # Reduced to 10 seconds for testing
            await asyncio.sleep(5)
        except Exception as e:
            print(f"Main loop error: {e}")
            await asyncio.sleep(5)


# loop = asyncio.get_running_loop()
# await loop.create_task(main())

if __name__ == "__main__":
    asyncio.run(main())